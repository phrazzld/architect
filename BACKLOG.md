# BACKLOG

- improve quality of synthesis prompt and output. investigate issues with ouput truncation

## Top Priorities

- [ ] **T25: Develop workflow engine**
  Develop a flexible multi-step workflow engine allowing users to define arbitrary sequences of operations (e.g., plan -> critique -> revise -> synthesize) via configuration or cli flags.
  * this might just be achieved by designing the program to support piping, ie take the multiple responses generated by the first pass and pipe them in as context for another pass

- [ ] **T37: Integrate with Claude Code**
  Investigate presenting `thinktank` itself as a tool to claude code, likely via mcp, defining its capabilities for planning, critique, and refinement

- [ ] **T14: Implement semantic versioning**
  Implement semantic versioning (ideally automatically managed somehow ... conventional commits?)

## Synthesis Feature Improvements (T13 follow-ups)

- [ ] **T13.1: Improve Error Context in Logs**
  Add better context to error logs in the orchestrator, including model name and operation phase. Use structured logging with sanitized error details instead of raw error formatting.

- [ ] **T13.2: Fix Leaky Abstraction in Error Handling**
  Refactor error handling to maintain strict separation of concerns. Have `processModels` return rich, self-describing errors that include model name and phase, so the orchestrator only needs to decide "log vs. return" rather than building error messages.

- [ ] **T13.3: Prevent Sensitive Data Exposure in Logs**
  Implement an `sanitizeError(err error)` helper to redact confidential information like API tokens, file paths, and stack traces from error logs.

- [ ] **T13.4: Improve Log Usability**
  Enhance warning messages with specific model names that failed, consolidate error logging approaches, and clarify code comments describing error handling logic.

- [ ] **T11: Audit codebase against dev philosophy**
  Audit whole codebase against dev philosophy, identify key things to hit

- [ ] add grok support for native grok api

- [ ] **T12: Code minimization**
  Remove as much as possible, shrink the codebase

- [ ] **T15: Improve arbitrary model handling**
  Improve arbitrary model handling

- [ ] **T16: Add Gemini grounding support**
  Add support for grounding with gemini models

- [ ] **T17: Refactor output handling**
  Refactor output handling to use standard streams (stdout for primary results, stderr for logs/errors) and add a json output mode flag (`--output-format json`) for machine-readable results.

- [ ] **T18: Use distinct exit codes**
  Use distinct exit codes for different outcomes (success, user error, api error, file system error) to allow programmatic result checking.

- [ ] **T19: Make file output optional**
  Make writing plan output to a file optional (`--output <path>`) and default to printing the plan to stdout if the flag is omitted

- [ ] **T20: Allow custom system prompts**
  Allow users to define and pass custom system prompts to the models.

- [ ] **T21: Enable custom model parameters**
  Enable users to provide full model configuration parameters (temperature, top-p, max output tokens, etc.) via cli flags or a configuration file

- [ ] **T22: Cache model metadata**
  Fetch, cache, and keep updated model metadata (e.g., max tokens, cost per token, input/output limits, usage tips) from provider apis or documentation for all supported models

- [ ] **T23: Implement token counting**
  Implement robust token counting using provider apis, display usage relative to model limits, warn if limits are approached, and potentially halt execution if limits are exceeded

- [ ] **T24: Estimate request costs**
  Estimate request cost based on token count and model pricing information, log the estimated cost, and potentially integrate with provider billing apis for accuracy.

- [ ] **T27: Implement built-in workflows**
  Implement a built-in plan -> critique -> refine workflow activated by a specific flag (e.g., `--critique-refine`).

- [ ] **T28: Add context preprocessing**
  Add an optional context preprocessing step to summarize large context inputs before sending them to the llm, potentially triggered automatically for models with smaller context windows.

- [ ] **T29: Auto-select appropriate models**
  Explore automatically selecting the most appropriate model or models based on the task description and context size/type.

- [ ] **T30: Integrate AST parsing**
  Integrate abstract syntax tree (ast) parsing for supported languages to provide richer structural context to the llm beyond raw text.

- [ ] **T31: Add git integration**
  Add git integration to use `git diff` output as context (`--context-git-diff <ref>`) or optionally include `git blame` / commit history for context files.

- [ ] **T32: Investigate language server integration**
  Investigate integrating with language servers or symbol indexing tools (ctags, sourcegraph api) to provide symbol definition/usage information as context.

- [ ] **T33: Support structured output formats**
  Support generating output plans in structured formats like json or yaml in addition to markdown.

- [ ] **T34: Add code generation mode**
  Add a code generation mode to attempt generating code snippets or files based on the generated plan.

- [ ] **T35: Provide patch file output**
  Provide an option to output suggested code changes (especially for refactoring) as a `.patch` file.

- [ ] **T36: Support Claude memory files**
  Make `thinktank` aware of claude code's memory files (`CLAUDE.md`, `CLAUDE.local.md`) to read configuration settings, respecting the same hierarchy

- [ ] **T38: Improve error messages**
  Review and significantly improve the clarity, detail, and actionability of all error messages throughout the application

- [ ] **T39: Add context metadata**
  Add metadata (file paths, git status) to the context provided to the llm.

- [ ] **T40: Add instruction enhancement**
  Support a "modify my instructions" flag that extracts intent from the passed instructions and sends it to a model to rewrite according to best prompt engineering practices before sending your actual request complete with context to your target models
## OpenAI Integration Improvements

- [ ] **T42: Consolidate API Services**
  Deprecate and remove the legacy `apiService` implementation to avoid confusion and inconsistent behavior between the legacy and registry implementations.

- [ ] **T43: Improve Model Name Lookup**
  Make model lookup in the registry case-insensitive to prevent user confusion with model capitalization.

- [ ] **T44: Standardize API Key Handling**
  Ensure consistent API key resolution logic across all code paths and providers to prevent subtle bugs.

- [ ] **T45: Restore Integration Tests**
  Update and re-enable the disabled integration tests to verify end-to-end functionality across all providers.

## Code Review Improvements

- [ ] **T46: Centralize Test Mocks**
  Refactor `internal/integration/multi_provider_test.go:122-141` to use shared mocks from `internal/testutil` instead of local mock definitions (`mockConfigLoader`, `mockProvider`) to reduce duplication.

- [ ] **T47: Evaluate BufferLogger Implementation**
  Review `internal/logutil/buffer_logger.go` to determine if standard library `log/slog` with `bytes.Buffer` could meet testing needs instead of a custom implementation, potentially reducing maintenance overhead.

- [ ] **T48: Remove Error Re-exports**
  Refactor tests currently relying on error re-exports in `cmd/thinktank/api.go:13-19` to import directly from `internal/llm` and remove the unnecessary `var (...)` block.

- [ ] **T49: Standardize Test File Naming**
  Consider renaming secret tests from `internal/providers/*/provider_secrets_test.go` to the more standard Go pattern `<provider>_secrets_test.go` (e.g., `gemini_secrets_test.go`).

- [ ] **T50: Remove Unnecessary Type Alias**
  Remove the alias `type APIService = interfaces.APIService` in `cmd/thinktank/api.go:22` and update internal usages to directly use `interfaces.APIService`.

- [ ] **T51: Improve Registry API Testability**
  Refactor `internal/thinktank/registry_api.go` to use interfaces instead of concrete types for dependencies, apply dependency injection pattern consistently, and add interface abstractions to make the code more testable without requiring extensive type assertions in tests. This will enhance long-term maintainability and enable more robust testing.
