// internal/integration/multi_model_test.go
package integration

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"testing"

	"github.com/phrazzld/architect/internal/architect"
	"github.com/phrazzld/architect/internal/gemini"
	"github.com/phrazzld/architect/internal/logutil"
)

// TestMultiModelExecution tests the execution with multiple models
func TestMultiModelExecution(t *testing.T) {
	// Set up the test environment
	env := NewTestEnv(t)
	defer env.Cleanup()

	// Save model names that were processed
	processedModels := make(map[string]bool)

	// Set up a custom mock client behavior to track model names
	env.MockClient.GenerateContentFunc = func(ctx context.Context, prompt string) (*gemini.GenerationResult, error) {
		// Extract the model name from the API service's InitClient call
		// This relies on the fact that we're setting a model-specific string in the result
		// to identify which model generated which content
		modelName := ctx.Value(modelNameKey).(string)
		processedModels[modelName] = true

		return &gemini.GenerationResult{
			Content:      "# Plan Generated by " + modelName + "\n\nThis is a test plan generated for the model.",
			TokenCount:   1000,
			FinishReason: "STOP",
		}, nil
	}

	// Create a test file
	env.CreateTestFile(t, "src/main.go", `package main

func main() {}`)

	// Create an instructions file
	instructionsFile := env.CreateTestFile(t, "instructions.md", "Test multi-model generation")

	// Set up the output directory
	outputDir := filepath.Join(env.TestDir, "output")

	// Create a test configuration with multiple models
	modelNames := []string{"model1", "model2", "model3"}
	testConfig := &architect.CliConfig{
		InstructionsFile: instructionsFile,
		OutputDir:        outputDir,
		ModelNames:       modelNames,
		ApiKey:           "test-api-key",
		Paths:            []string{env.TestDir + "/src"},
		LogLevel:         logutil.InfoLevel,
	}

	// Create a custom mock API service that can track model names
	mockAPIService := &mockModelTrackingAPIService{
		logger:     env.Logger,
		mockClient: env.MockClient,
	}

	// Run the application directly with our custom mock API service
	ctx := context.Background()
	err := architect.RunInternal(
		ctx,
		testConfig,
		env.Logger,
		mockAPIService,
		env.AuditLogger,
	)

	if err != nil {
		t.Fatalf("RunInternal failed: %v", err)
	}

	// Check that the output directory exists
	if _, err := os.Stat(outputDir); os.IsNotExist(err) {
		t.Errorf("Output directory was not created at %s", outputDir)
	}

	// Check that we have a separate output file for each model
	for _, modelName := range modelNames {
		// Construct the expected file path (as the implementation would)
		outputFile := filepath.Join(outputDir, modelName+".md")

		// Check that the file exists
		if _, err := os.Stat(outputFile); os.IsNotExist(err) {
			t.Errorf("Output file for model %s was not created at %s", modelName, outputFile)
			continue
		}

		// Read the content to verify it contains model-specific content
		content, err := os.ReadFile(outputFile)
		if err != nil {
			t.Errorf("Failed to read output file for model %s: %v", modelName, err)
			continue
		}

		// Verify the content contains the model name
		if !strings.Contains(string(content), "Plan Generated by "+modelName) {
			t.Errorf("Output file for model %s does not contain model-specific content. Content: %s",
				modelName, string(content))
		}
	}

	// Verify that all models were processed
	for _, modelName := range modelNames {
		if !processedModels[modelName] {
			t.Errorf("Model %s was not processed", modelName)
		}
	}
}

// Define a type for the context key to avoid string collisions
type contextKey string

// Define a constant for the model name key
const modelNameKey contextKey = "current_model"

// mockModelTrackingAPIService extends mockIntAPIService to track model names
type mockModelTrackingAPIService struct {
	logger     logutil.LoggerInterface
	mockClient gemini.Client
}

// InitClient returns the mock client and stores model name in context
func (s *mockModelTrackingAPIService) InitClient(ctx context.Context, apiKey, modelName string) (gemini.Client, error) {
	// Create a new context with the model name
	ctx = context.WithValue(ctx, modelNameKey, modelName)

	// Set the context in the mock client
	mockClient := &modelAwareClient{
		delegateClient: s.mockClient,
		ctx:            ctx,
	}

	return mockClient, nil
}

// Process responses the same as mockIntAPIService
func (s *mockModelTrackingAPIService) ProcessResponse(result *gemini.GenerationResult) (string, error) {
	if result == nil {
		return "", fmt.Errorf("empty response from API")
	}
	if result.Content == "" {
		return "", fmt.Errorf("empty content from API")
	}
	return result.Content, nil
}

func (s *mockModelTrackingAPIService) IsEmptyResponseError(err error) bool {
	if err == nil {
		return false
	}
	return strings.Contains(err.Error(), "empty")
}

func (s *mockModelTrackingAPIService) IsSafetyBlockedError(err error) bool {
	if err == nil {
		return false
	}
	return strings.Contains(err.Error(), "safety")
}

func (s *mockModelTrackingAPIService) GetErrorDetails(err error) string {
	if err == nil {
		return ""
	}
	return err.Error()
}

// modelAwareClient wraps a Client to preserve the context with model name
type modelAwareClient struct {
	delegateClient gemini.Client
	ctx            context.Context
}

func (c *modelAwareClient) GenerateContent(ctx context.Context, prompt string) (*gemini.GenerationResult, error) {
	// Use the stored context that has the model name instead of the provided one
	return c.delegateClient.GenerateContent(c.ctx, prompt)
}

func (c *modelAwareClient) CountTokens(ctx context.Context, prompt string) (*gemini.TokenCount, error) {
	return c.delegateClient.CountTokens(ctx, prompt)
}

func (c *modelAwareClient) GetModelInfo(ctx context.Context) (*gemini.ModelInfo, error) {
	return c.delegateClient.GetModelInfo(ctx)
}

func (c *modelAwareClient) Close() error {
	return c.delegateClient.Close()
}

// TestModelFailureHandling tests the behavior when one model fails but others succeed
func TestModelFailureHandling(t *testing.T) {
	// Set up the test environment
	env := NewTestEnv(t)
	defer env.Cleanup()

	// Track model processing attempts
	processedModels := make(map[string]bool)
	failedModels := make(map[string]bool)

	// Set up a custom mock client behavior to make the second model fail
	env.MockClient.GenerateContentFunc = func(ctx context.Context, prompt string) (*gemini.GenerationResult, error) {
		// Extract the model name
		modelName := ctx.Value(modelNameKey).(string)
		processedModels[modelName] = true

		// Make model2 fail
		if modelName == "model2" {
			failedModels[modelName] = true
			return nil, fmt.Errorf("simulated error for model %s", modelName)
		}

		return &gemini.GenerationResult{
			Content:      "# Plan Generated by " + modelName + "\n\nThis is a test plan generated for the model.",
			TokenCount:   1000,
			FinishReason: "STOP",
		}, nil
	}

	// Create a test file
	env.CreateTestFile(t, "src/main.go", `package main

func main() {}`)

	// Create an instructions file
	instructionsFile := env.CreateTestFile(t, "instructions.md", "Test multi-model generation with error handling")

	// Set up the output directory
	outputDir := filepath.Join(env.TestDir, "output")

	// Create a test configuration with multiple models
	modelNames := []string{"model1", "model2", "model3"}
	testConfig := &architect.CliConfig{
		InstructionsFile: instructionsFile,
		OutputDir:        outputDir,
		ModelNames:       modelNames,
		ApiKey:           "test-api-key",
		Paths:            []string{env.TestDir + "/src"},
		LogLevel:         logutil.InfoLevel,
	}

	// Create a custom mock API service that can track model names
	mockAPIService := &mockModelTrackingAPIService{
		logger:     env.Logger,
		mockClient: env.MockClient,
	}

	// Run the application directly with our custom mock API service
	ctx := context.Background()
	err := architect.RunInternal(
		ctx,
		testConfig,
		env.Logger,
		mockAPIService,
		env.AuditLogger,
	)

	// Should have an error because model2 failed
	if err == nil {
		t.Fatalf("Expected RunInternal to fail due to model2 error, but it succeeded")
	}

	// Error should mention model2
	if !strings.Contains(err.Error(), "model2") {
		t.Errorf("Error message does not mention failed model: %v", err)
	}

	// Check that the output directory exists
	if _, err := os.Stat(outputDir); os.IsNotExist(err) {
		t.Errorf("Output directory was not created at %s", outputDir)
	}

	// Check output files for successful models
	for _, modelName := range []string{"model1", "model3"} {
		outputFile := filepath.Join(outputDir, modelName+".md")

		// Check that the file exists
		if _, err := os.Stat(outputFile); os.IsNotExist(err) {
			t.Errorf("Output file for successful model %s was not created at %s", modelName, outputFile)
			continue
		}

		// Read the content to verify it contains model-specific content
		content, err := os.ReadFile(outputFile)
		if err != nil {
			t.Errorf("Failed to read output file for model %s: %v", modelName, err)
			continue
		}

		// Verify the content contains the model name
		if !strings.Contains(string(content), "Plan Generated by "+modelName) {
			t.Errorf("Output file for model %s does not contain model-specific content", modelName)
		}
	}

	// Check that the failed model doesn't have an output file
	failedOutputFile := filepath.Join(outputDir, "model2.md")
	if _, err := os.Stat(failedOutputFile); !os.IsNotExist(err) {
		t.Errorf("Output file for failed model was created at %s (it shouldn't exist)", failedOutputFile)
	}

	// Verify that all models were attempted
	for _, modelName := range modelNames {
		if !processedModels[modelName] {
			t.Errorf("Model %s was not attempted", modelName)
		}
	}

	// Verify that only model2 failed
	if !failedModels["model2"] {
		t.Errorf("Expected model2 to fail, but it didn't")
	}
	if len(failedModels) != 1 {
		t.Errorf("Expected exactly one model to fail, but got %d failed models", len(failedModels))
	}
}

// TestBackwardCompatibility tests that our implementation maintains backward compatibility
// by writing both model-specific files and the traditional output.md file
func TestBackwardCompatibility(t *testing.T) {
	// Set up the test environment
	env := NewTestEnv(t)
	defer env.Cleanup()

	// Set up the mock client
	env.SetupMockGeminiClient()

	// Create a test file
	env.CreateTestFile(t, "src/main.go", `package main

func main() {}`)

	// Create an instructions file
	instructionsFile := env.CreateTestFile(t, "instructions.md", "Test backward compatibility")

	// Set up the output directory
	outputDir := filepath.Join(env.TestDir, "output")

	// Create a test configuration with a single model (traditional case)
	testConfig := &architect.CliConfig{
		InstructionsFile: instructionsFile,
		OutputDir:        outputDir,
		ModelNames:       []string{"gemini-pro"},
		ApiKey:           "test-api-key",
		Paths:            []string{env.TestDir + "/src"},
		LogLevel:         logutil.InfoLevel,
	}

	// Run the application
	ctx := context.Background()
	err := RunTestWithConfig(ctx, testConfig, env)

	if err != nil {
		t.Fatalf("RunTestWithConfig failed: %v", err)
	}

	// Check that the output directory exists
	if _, err := os.Stat(outputDir); os.IsNotExist(err) {
		t.Errorf("Output directory was not created at %s", outputDir)
	}

	// Check that both files exist:
	// 1. The model-specific file
	modelOutputFile := filepath.Join(outputDir, "gemini-pro.md")
	if _, err := os.Stat(modelOutputFile); os.IsNotExist(err) {
		t.Errorf("Model-specific output file was not created at %s", modelOutputFile)
	}

	// 2. The legacy output.md file
	legacyOutputFile := filepath.Join(outputDir, "output.md")
	if _, err := os.Stat(legacyOutputFile); os.IsNotExist(err) {
		t.Errorf("Legacy output.md file was not created at %s", legacyOutputFile)
	}

	// Check that the content is identical in both files
	modelContent, err := os.ReadFile(modelOutputFile)
	if err != nil {
		t.Fatalf("Failed to read model-specific output file: %v", err)
	}

	legacyContent, err := os.ReadFile(legacyOutputFile)
	if err != nil {
		t.Fatalf("Failed to read legacy output file: %v", err)
	}

	if string(modelContent) != string(legacyContent) {
		t.Errorf("Content mismatch between model-specific file and legacy output.md file")
	}
}
