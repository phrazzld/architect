# Profile Analysis Workflow

This document describes the workflow for analyzing test profiles to identify performance hotspots in the Architect project.

## Generating Profiles

### Local Generation

To generate profiles locally, use the `scripts/profile_tests.sh` script:

```bash
# Basic usage (profiles all packages)
./scripts/profile_tests.sh

# Profile a specific package
./scripts/profile_tests.sh --package=./internal/fileutil

# Run with custom test arguments
./scripts/profile_tests.sh --test-args="-v -run=TestXyz"

# Launch interactive pprof shell after generation
./scripts/profile_tests.sh --interactive
```

### Using CI-Generated Profiles

Alternatively, you can use profiles generated by the CI pipeline:

1. Trigger the "Go CI" workflow in GitHub Actions with the "Run tests with profiling" option
2. Download the `test-profiles` artifact after the workflow completes
3. Extract the artifact and analyze the profiles using the steps below

## Analyzing Profiles

### Initial Assessment

1. Review the automatically generated `cpu_top.txt` and `mem_top.txt` reports
2. If available, examine the `cpu_graph.png` and `mem_graph.png` visualizations
3. Identify the top functions consuming CPU time and memory

### Interactive Analysis

For deeper analysis, use the interactive `pprof` tool:

```bash
# CPU profile analysis
go tool pprof profile_data/cpu.prof

# Memory profile analysis
go tool pprof profile_data/mem.prof

# Block profile analysis (concurrency issues)
go tool pprof profile_data/block.prof
```

Within the `pprof` shell, use these commands:

- `top N` - Show the top N functions by resource usage
- `list function_name` - Show the source code for a function with profiling data
- `web` - Generate a graph visualization (requires graphviz)
- `peek function_name` - Show callers/callees of a function
- `traces` - Show sample execution traces

### Web UI Analysis

For a more visual analysis, use the pprof HTTP interface:

```bash
go tool pprof -http=:8080 profile_data/cpu.prof
```

This starts a web server on port 8080 with an interactive UI for exploring the profiling data.

### Common Hotspot Patterns to Look For

- **File I/O Operations**: Look for excessive file reads/writes
- **Token Counting**: Check if token estimation is inefficient
- **String Processing**: Identify inefficient string manipulations
- **Regular Expressions**: Regex compilation and execution can be expensive
- **Concurrency Management**: Look for contention in rate limiting and synchronization
- **Test Setup**: Identify tests with expensive setup/teardown
- **Binary File Detection**: The `isBinaryFile` function might be inefficient
- **Memory Allocations**: Functions allocating excessive memory

## Documenting Findings

Document your findings in a structured format:

1. **Summary of Key Hotspots**: List the top 3-5 functions consuming the most resources
2. **Detailed Analysis**: For each hotspot, provide:
   - Function name and location
   - Resource consumption metrics (CPU time, memory allocations)
   - Potential causes and context
   - Suggestions for optimization
3. **Visualization**: Include relevant graphs or screenshots
4. **Action Items**: List concrete steps for addressing the identified hotspots

## Performance Optimizations

When optimizing identified hotspots, consider these strategies:

1. **Reduce Allocations**: Minimize memory allocations in hot paths
2. **Caching**: Cache expensive computation results
3. **Buffering**: Use buffered I/O for file operations
4. **Concurrency**: Parallelize independent operations
5. **Algorithm Improvements**: Replace O(nÂ²) algorithms with O(n) or O(log n) alternatives
6. **Precompile Regexes**: Compile regular expressions once and reuse them

Always benchmark before and after optimization to confirm improvements.